# PRISM â€” Predictive Representation for Introspective Spatial Metacognition

> Premier test computationnel de la thÃ¨se neuroscientifique de la mÃ©ta-carte hippocampique :
> la successor representation comme substrat unifiÃ© pour la cognition et la mÃ©tacognition,
> Ã©valuÃ© avec les outils de la psychophysique.

---

## 1. Revue de littÃ©rature

### 1.1 Successor representations â€” fondements

Le formalisme des successor representations a Ã©tÃ© introduit par **Dayan (1993)** comme compromis entre apprentissage model-free (efficace mais rigide) et model-based (flexible mais coÃ»teux). L'idÃ©e centrale est la dÃ©composition de la fonction de valeur V(s) = M Â· R, oÃ¹ M encode les transitions prÃ©dites et R les rÃ©compenses, permettant une adaptation rapide quand l'un change indÃ©pendamment de l'autre.

**Stachenfeld, Botvinick & Gershman (2017, Nature Neuroscience)** ont reformulÃ© l'hippocampe comme "carte prÃ©dictive" : les cellules de lieu CA1 n'encodent pas la position gÃ©odÃ©sique mais la probabilitÃ© de transition vers les positions futures. Les grid cells du cortex entorhinal Ã©mergent comme eigenvectors de la matrice SR â€” une compression spectrale multi-Ã©chelle. Cette thÃ©orie prÃ©dit et explique l'expansion asymÃ©trique des champs de lieu, le clustering, la sensibilitÃ© Ã  la rÃ©compense et les cellules de temps.

**Gershman (2018, J. Neuroscience)** a fourni une synthÃ¨se de la logique computationnelle et des substrats neuronaux de la SR, Ã©tablissant qu'elle ne fonctionne pas en isolation mais interagit avec des computations model-based et model-free.

**Momennejad, Russek et al. (2017, Nature Human Behaviour)** ont fourni les premiÃ¨res preuves comportementales chez l'humain : les sujets montrent une sensibilitÃ© aux changements de rÃ©compense (comme prÃ©dit par la SR) mais une insensibilitÃ© aux changements de transition (signature unique de la SR vs. model-based). Leurs donnÃ©es montrent un modÃ¨le hybride SRâ€“MB.

**Russek, Momennejad et al. (2017, PLoS Comp Bio)** ont formalisÃ© comment les computations model-based peuvent Ãªtre construites sur un socle de TD learning via la SR, avec des extensions Dyna-SR qui utilisent le replay hippocampique pour mettre Ã  jour la matrice M offline.

### 1.2 Au-delÃ  de l'espace physique â€” espaces cognitifs

**Bellmund et al. (2018, Science)** ont montrÃ© que les codes spatiaux hippocampiques opÃ¨rent sur des "espaces cognitifs" abstraits â€” des espaces dont les dimensions peuvent Ãªtre le poids, la hiÃ©rarchie sociale, ou les features sÃ©mantiques.

**Theves, Fernandez & Doeller (2020, J. Neuroscience)** ont prouvÃ© que l'hippocampe cartographie l'espace conceptuel plutÃ´t que l'espace des features bruts : le signal de distance hippocampique reflÃ¨te sÃ©lectivement les dimensions conceptuellement pertinentes.

**Stoewer et al. (2023, Scientific Reports)** ont dÃ©montrÃ© que des rÃ©seaux de neurones artificiels apprenant des SR sur des espaces sÃ©mantiques (32 espÃ¨ces animales) construisent avec succÃ¨s des cartes cognitives capturant les similaritÃ©s entre concepts.

**Ekman et al. (2023, eLife)** ont montrÃ© que le cortex visuel primaire V1 et l'hippocampe reprÃ©sentent une carte prÃ©dictive apparentÃ©e Ã  la SR â€” les reprÃ©sentations prÃ©dictives imprÃ¨gnent le traitement perceptif lui-mÃªme.

### 1.3 Hippocampe et mÃ©tacognition â€” la thÃ¨se de la mÃ©ta-carte

Le lien le plus direct avec PRISM provient de la thÃ¨se de la **mÃ©ta-carte hippocampique** proposÃ©e par **Ambrogioni & Ã“lafsdÃ³ttir (2023, Trends in Cognitive Sciences)** â€” Â« Rethinking the hippocampal cognitive map as a meta-learning computational module Â» : l'hippocampe n'encode pas seulement des cartes d'environnements familiers, mais aussi des Ã©tats informationnels et des sources d'information. Les cartes cognitives feraient partie d'une mÃ©ta-reprÃ©sentation plus large qui soutient l'exploration et fournit un fondement pour l'apprentissage en contexte d'incertitude.

**Allen et al. (2017, NeuroImage)** ont montrÃ© par IRM quantitative que la capacitÃ© mÃ©tacognitive corrÃ¨le avec la microstructure de l'hippocampe et du cortex prÃ©frontal antÃ©rieur â€” confirmation neuroanatomique que mÃ©tacognition et cognition spatiale partagent des substrats.

**Qiu et al. (2024, Communications Biology)** ont confirmÃ© en IRMf que l'hippocampe, le cortex entorhinal et le cortex orbitofrontal collaborent pour apprendre la structure d'espaces abstraits multidimensionnels.

### 1.4 SR et incertitude â€” travaux existants

**Janz et al. (2019, NeurIPS) â€” Successor Uncertainties.** Combinaison de successor features avec la rÃ©gression linÃ©aire bayÃ©sienne pour propager l'incertitude Ã  travers la structure temporelle du MDP. L'incertitude guide l'exploration via posterior sampling (PSRL). Surpasse la performance humaine sur 38/49 jeux Atari. C'est le travail le plus proche de PRISM sur l'axe SR + incertitude.

**Machado, Bellemare & Bowling (2020, AAAI) â€” Count-based exploration with SR.** Utilisent la norme de la SR comme proxy pour les visites d'Ã©tats, dÃ©rivant des bonus d'exploration count-based Ã  partir de la structure SR.

**Flennerhag et al. (2020, DeepMind) â€” Temporal Difference Uncertainties as Signal for Exploration.** Proposent d'utiliser les incertitudes des diffÃ©rences temporelles comme signal d'exploration, conceptuellement proche du monitoring d'erreurs TD de PRISM.

### 1.5 MÃ©tacognition en IA â€” frameworks existants

**Valiente & Pilly (2024, arXiv; 2025, Neural Networks) â€” MUSE Framework.** IntÃ¨gre self-assessment et self-regulation dans des agents autonomes. Deux implÃ©mentations : world model et LLM. TestÃ© dans Meta-World et ALFWorld. Le framework le plus complet pour la mÃ©tacognition computationnelle, mais n'utilise pas la SR comme substrat.

**Kawato et al. (2021, Biological Cybernetics) â€” From Internal Models toward Metacognitive AI.** Propose un modÃ¨le computationnel de la mÃ©tacognition basÃ© sur des paires de modÃ¨les gÃ©nÃ©ratifs-inverses avec un "responsibility signal" qui gate la sÃ©lection et l'apprentissage. Le signal de responsabilitÃ© est conceptuellement proche du monitoring d'erreurs de prÃ©diction de PRISM.

**Meta-Cognitive RL (VPES).** Framework rÃ©cent oÃ¹ un mÃ©ta-contrÃ´leur monitore la stabilitÃ© des erreurs de prÃ©diction de valeur (Value Prediction Error Stability) pour rÃ©guler le taux d'apprentissage. Architecturalement proche de la mÃ©ta-SR de PRISM.

**Steyvers & Peters (2025, Perspectives on Psychological Science).** Survey sur la mÃ©tacognition et la communication d'incertitude chez les humains et les LLMs, identifiant la calibration de confiance comme mÃ©trique clÃ©.

### 1.6 Cadre englobant â€” l'Espace de Travail Neuronal Global (GNW)

La Global Neuronal Workspace de **Dehaene & Changeux (1998, 2011)** est la thÃ©orie dominante de l'accÃ¨s conscient : des neurones pyramidaux Ã  axones longs (prÃ©frontaux, pariÃ©taux) forment un workspace global oÃ¹ l'information subit une "ignition" non-linÃ©aire, tout-ou-rien, la rendant accessible Ã  l'ensemble des processeurs spÃ©cialisÃ©s. La GNW est une thÃ©orie du **broadcast** â€” ce qui entre dans le workspace devient conscient.

Deux rÃ©sultats rendent la GNW pertinente pour PRISM :

**L'hippocampe fait partie du core du workspace.** Deco, Vidaurre & Kringelbach (2021, *Nature Human Behaviour*) ont quantifiÃ© empiriquement le "functional rich club" constituant le workspace global Ã  travers sept tÃ¢ches + repos. L'hippocampe figure dans le noyau central, aux cÃ´tÃ©s du precuneus, du cingulaire postÃ©rieur et du noyau accumbens. La carte prÃ©dictive SR n'est donc pas un processus pÃ©riphÃ©rique isolÃ© â€” elle alimente directement le hub de diffusion global.

**Le "predictive global workspace".** Whyte & Smith (2020, *Progress in Neurobiology*) intÃ¨grent la GNW avec l'active inference de Friston, montrant que le workspace peut Ãªtre compris comme le lieu oÃ¹ les erreurs de prÃ©diction sont sÃ©lectionnÃ©es et diffusÃ©es. PRISM opÃ¨re exactement dans cet espace d'erreurs de prÃ©diction â€” en amont du broadcast.

La GNW et PRISM opÃ¨rent Ã  des Ã©chelles diffÃ©rentes et ne sont pas en compÃ©tition. La GNW dÃ©crit comment l'information mÃ©tacognitive devient **globalement accessible**. PRISM dÃ©crit **d'oÃ¹ elle vient** â€” le monitoring de la structure prÃ©dictive SR au sein du module hippocampique. Le positionnement prÃ©cis est dÃ©veloppÃ© en Â§3.4.

---

## 2. Revue des rÃ©sultats et implÃ©mentations existants

### 2.1 Ce qui a Ã©tÃ© dÃ©montrÃ© expÃ©rimentalement

| RÃ©sultat | Auteurs | Statut |
|----------|---------|--------|
| SR tabulaire converge dans FourRooms | Juliani (2019, tutorial) | âœ… Reproduit, code dispo |
| Eigenvectors de M â†’ patterns grid-like | Stachenfeld et al. (2017); Chelu (repo) | âœ… Reproduit, code dispo |
| Transfert SR quand R change (M rÃ©utilisÃ©) | Juliani (2019); Barreto et al. (2017) | âœ… Reproduit, code dispo |
| Humains utilisent SR + arbitrage SR/MB | Momennejad et al. (2017) | âœ… DonnÃ©es + modÃ¨le dispo |
| SR + incertitude bayÃ©sienne â†’ exploration | Janz et al. (2019) | âœ… RÃ©sultats Atari-scale |
| Count-based exploration via norme SR | Machado et al. (2020) | âœ… RÃ©sultats AAAI |
| SF apprises depuis pixels dans MiniGrid | Chua et al. (2024) | âœ… Code dispo |
| MÃ©tacognition comme self-assessment RL | Valiente & Pilly (2024) | âœ… Meta-World + ALFWorld |

### 2.2 Ce qui n'a PAS Ã©tÃ© fait

| Gap | Pourquoi c'est un gap | PRISM le comble ? |
|-----|----------------------|-------------------|
| Carte d'incertitude iso-structurale Ã  la SR | Successor Uncertainties propage l'incertitude mais ne construit pas une carte spatiale parallÃ¨le | âœ… Contribution principale |
| Calibration psychophysique d'un agent SR | Personne n'a mesurÃ© l'ECE d'un agent SR ni produit de reliability diagram | âœ… Protocole Exp A |
| Signal "je ne sais pas" calibrÃ© et continu | MUSE fait du self-assessment mais sans mÃ©triques de calibration formelles | âœ… Protocole Exp A |
| Test computationnel de la mÃ©ta-carte hippocampique | La thÃ¨se TiCS 2023 est thÃ©orique, jamais implÃ©mentÃ©e | âœ… Cadrage du projet |
| Exploration dirigÃ©e par incertitude SR structurale | Machado (2020) utilise la norme SR ; Janz (2019) utilise le posterior â€” ni l'un ni l'autre n'utilise une carte U(s) parallÃ¨le | âœ… Protocole Exp B |
| Comparaison incertitude SR structurale vs. bayÃ©sienne vs. count-based | Chaque approche a Ã©tÃ© Ã©valuÃ©e isolÃ©ment | âœ… Protocole Exp B |

### 2.3 Assets rÃ©utilisables

| Asset | Source | Usage dans PRISM |
|-------|--------|-----------------|
| **MiniGrid** FourRooms | Farama Foundation (NeurIPS 2023) | Environnement de base â€” pas de gridworld custom |
| SR tabulaire + visualisations | Juliani (2019) | Point de dÃ©part pour l'agent SR |
| DÃ©composition spectrale SR | Chelu (github/temporal_abstraction) | Visualisation eigenvectors, eigenvalues |
| ModÃ¨le SR/MB hybride | Russek et al. (2017, github) | RÃ©fÃ©rence pour l'arbitrage |
| Simple Successor Features | Chua et al. (2024, github) | Deep SF si extension future |
| Baselines RL | Stable-Baselines3 | Q-learning, DQN baselines |

---

## 3. Positionnement de PRISM

### 3.1 Carte de positionnement

```
    Axe Y : Rigueur mÃ©tacognitive (mÃ©triques psychophysiques)
    Ã¢â€“Â²
    â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   â”‚  PRISM  â”‚  SR comme substrat naturel pour la mÃ©tacognition
    â”‚   â”‚         â”‚  Calibration ECE, reliability diagrams
    â”‚   â”‚         â”‚  Carte d'incertitude iso-structurale
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚        â–²
    â”‚        â”‚ apporte les mÃ©triques        apporte le substrat SR
    â”‚        â”‚ mÃ©tacognitives                    â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   â”‚  MUSE   â”‚                    â”‚ Succ. Uncertain. â”‚
    â”‚   â”‚         â”‚                    â”‚                  â”‚
    â”‚   â”‚ Self-assessment              â”‚ SR + bayÃ©sien    â”‚
    â”‚   â”‚ Self-regulation              â”‚ pour exploration â”‚
    â”‚   â”‚ (world model / LLM)          â”‚ (posterior samp.)â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Axe X : Ancrage SR
    â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   â”‚ VPES /    â”‚          â”‚ Machado 2020 â”‚
    â”‚   â”‚ Meta-Cog  â”‚          â”‚ Count + SR   â”‚
    â”‚   â”‚ RL        â”‚          â”‚              â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Contribution unique

**PRISM est le premier projet Ã  :**

1. Construire une **carte d'incertitude iso-structurale** Ã  la SR â€” mÃªme formalisme pour cognition de premier ordre (M : "oÃ¹ vais-je ?") et mÃ©tacognition (U : "est-ce que je sais oÃ¹ je vais ?")

2. Mesurer la **calibration mÃ©tacognitive** d'un agent SR avec les outils de la psychophysique (ECE, reliability diagrams, Metacognitive Index) â€” traiter un agent RL comme un sujet de psychologie cognitive

3. **Tester computationnellement** la thÃ¨se de la mÃ©ta-carte hippocampique (TiCS, 2023), en montrant que la structure prÃ©dictive de la SR suffit Ã  faire Ã©merger des comportements mÃ©tacognitifs sans module mÃ©tacognitif externe

### 3.3 Ce que PRISM ne prÃ©tend PAS faire

- Surpasser Successor Uncertainties en performance d'exploration (ils opÃ¨rent Ã  l'Ã©chelle Atari, PRISM est tabulaire)
- Remplacer MUSE comme framework gÃ©nÃ©ral de mÃ©tacognition (PRISM est spÃ©cifique au substrat SR)
- Prouver que le cerveau utilise la mÃ©ta-SR (PRISM est un test computationnel, pas une validation neurobiologique)
- ModÃ©liser la conscience ou l'accÃ¨s conscient (c'est le territoire de la GNW, voir ci-dessous)

### 3.4 Positionnement par rapport Ã  l'Espace de Travail Neuronal Global (GNW)

La Global Neuronal Workspace de Dehaene-Changeux (1998, 2011) est la thÃ©orie dominante de l'accÃ¨s conscient. PRISM et la GNW ne sont pas en compÃ©tition â€” ils opÃ¨rent Ã  des Ã©chelles diffÃ©rentes.

**PRISM modÃ©lise un processeur spÃ©cialisÃ© qui alimente le workspace.** L'hippocampe fait partie du noyau central du workspace global (Deco et al., 2021). La carte prÃ©dictive SR et la mÃ©ta-carte U(s) produisent des signaux â€” erreurs de prÃ©diction, incertitude â€” qui peuvent Ãªtre diffusÃ©s vers le workspace. PRISM modÃ©lise la **computation locale** qui gÃ©nÃ¨re ces signaux. La GNW modÃ©lise comment ils deviennent **globalement accessibles**.

| | GNW (Dehaene-Changeux) | PRISM |
|---|---|---|
| Ã‰chelle | Cerveau entier | Module hippocampique |
| MÃ©canisme clÃ© | Ignition + broadcast | Erreur de prÃ©diction SR + mÃ©ta-carte |
| Question centrale | Comment l'information devient consciente ? | D'oÃ¹ vient le signal d'incertitude ? |
| MÃ©tacognition | Requiert l'accÃ¨s au workspace | Ã‰merge de la structure prÃ©dictive locale |
| Dynamique | Tout-ou-rien (seuil d'ignition) | Continue (U(s)) + seuil (dÃ©tection changement) |

**Point de contact clÃ© â€” le seuil de dÃ©tection.** La **dÃ©tection de changement** de PRISM â€” quand `change_score > Î¸_change` â€” a la structure d'un seuil d'ignition GNW : une transition discrÃ¨te qui rÃ©oriente la stratÃ©gie de l'agent. Le `Î¸_change` pourrait Ãªtre l'analogue fonctionnel du seuil d'ignition, local Ã  l'hippocampe. Tester si ce seuil exhibe les propriÃ©tÃ©s de l'ignition (non-linÃ©aritÃ©, hystÃ©rÃ©sis) est une extension future hors-scope de la v1.

---

## 4. ThÃ¨se resserrÃ©e

### HypothÃ¨se principale

> La successor representation fournit un substrat **naturel** pour la mÃ©tacognition :
> une carte d'incertitude construite Ã  partir des erreurs de prÃ©diction SR
> (iso-structurale Ã  la carte prÃ©dictive elle-mÃªme) produit des signaux de confiance
> **mieux calibrÃ©s** que les approches d'incertitude non-structurÃ©es,
> et cela soutient la thÃ¨se neuroscientifique de la mÃ©ta-carte hippocampique.

### PrÃ©dictions testables

**P1 â€” Calibration.** Le signal de confiance C(s) dÃ©rivÃ© de la mÃ©ta-SR est calibrÃ© : les dÃ©cisions Ã  haute confiance sont correctes plus souvent que les dÃ©cisions Ã  basse confiance. ECE < 0.15.

**P2 â€” Iso-structuralitÃ©.** La carte d'incertitude U(s) a une structure spatiale cohÃ©rente avec la carte prÃ©dictive M : les frontiÃ¨res d'incertitude correspondent aux frontiÃ¨res topologiques du monde (portes, zones inexplorÃ©es, zones rÃ©cemment modifiÃ©es).

**P3 â€” Avantage de la structure.** L'exploration guidÃ©e par U(s) (structurÃ©e spatialement) est plus efficace que l'exploration guidÃ©e par des signaux d'incertitude non-structurÃ©s (count-based, Îµ-greedy, variance globale).

---

## 5. Architecture

### 5.1 Vue d'ensemble

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MONDE â€” MiniGrid FourRooms                  â”‚
â”‚  (Farama Foundation, asset existant)                     â”‚
â”‚  + DynamicsWrapper (Ã  coder)                             â”‚
â”‚    - DÃ©placement de rÃ©compense                           â”‚
â”‚    - Blocage/ouverture de porte                          â”‚
â”‚    - Schedule de perturbations                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ (s, a, r, s')
                         Ã¢â€“Â¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AGENT PRISM                              â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Couche SR â€” premier ordre                     â”‚      â”‚
â”‚  â”‚  (adaptÃ© de Juliani 2019 / Chua et al. 2024)   â”‚      â”‚
â”‚  â”‚  M(s,s') : transitions prÃ©dites (TD learning)  â”‚      â”‚
â”‚  â”‚  R(s) : rÃ©compenses apprises                   â”‚      â”‚
â”‚  â”‚  V(s) = M Â· R                                  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                        â”‚ Î´(s) = || TD error on M ||       â”‚
â”‚                        â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Couche MÃ©ta-SR â€” CONTRIBUTION PRISM â˜…         â”‚      â”‚
â”‚  â”‚  U(s) : carte d'incertitude (buffer Î´ glissant)â”‚      â”‚
â”‚  â”‚  C(s) : signal de confiance calibrÃ©            â”‚      â”‚
â”‚  â”‚  DÃ©tection de changement structurel            â”‚      â”‚
â”‚  â”‚  Iso-structurale Ã  M par construction          â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                        â”‚ C(s), U(s)                       â”‚
â”‚                        â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  ContrÃ´leur                                    â”‚      â”‚
â”‚  â”‚  Îµ_adaptive(s) = f(U(s))                       â”‚      â”‚
â”‚  â”‚  V_explore(s) = V(s) + Î» Â· U(s)               â”‚      â”‚
â”‚  â”‚  Signal "je ne sais pas" quand C(s) < Î¸        â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Le monde â€” MiniGrid + DynamicsWrapper

**Base :** `MiniGrid-FourRooms-v0` (Farama Foundation). Grille modulaire avec 4 piÃ¨ces connectÃ©es par des portes. Interface Gymnasium standard.

**Extension custom â€” `DynamicsWrapper` :** Wrapper Gymnasium qui ajoute les perturbations dynamiques au-dessus de n'importe quel env MiniGrid. C'est le seul composant "monde" Ã  coder.

```python
class DynamicsWrapper(gymnasium.Wrapper):
    """Ajoute des perturbations contrÃ´lÃ©es Ã  un env MiniGrid."""
    
    def apply_perturbation(self, ptype: str, **kwargs):
        """Types : 'reward_shift', 'door_block', 'door_open', 'combined'"""
    
    def set_schedule(self, schedule: PerturbationSchedule):
        """Schedule configurable : pÃ©riodique, alÃ©atoire, triggered."""
    
    def get_state_index(self, pos: tuple) -> int:
        """Mapping position â†’ index d'Ã©tat pour la matrice SR."""
    
    def get_true_transition_matrix(self) -> np.ndarray:
        """Ground truth pour validation."""
```

### 5.3 La couche SR â€” premier ordre

AdaptÃ© depuis les implÃ©mentations existantes (Juliani 2019). Pas de contribution ici â€” c'est un composant standard.

**Matrice SR â€” M âˆˆ â„^(NÃ—N) :**

```
M(s, s') = E[ Î£_t Î³^t ğŸ™(s_t = s') | s_0 = s, Ï€ ]
```

**Mise Ã  jour TD(0) :**

```
Î´_M(s) = e(s') + Î³ Â· M(s',:) - M(s,:)
M(s,:) â† M(s,:) + Î±_M Â· Î´_M(s)
```

**Fonction de valeur :** V(s) = M(s,:) Â· R

**ParamÃ¨tres :**

| ParamÃ¨tre | Symbole | DÃ©faut | RÃ´le |
|-----------|---------|--------|------|
| Discount factor | Î³ | 0.95 | Horizon temporel SR |
| Learning rate SR | Î±_M | 0.1 | Vitesse d'apprentissage M |
| Learning rate R | Î±_R | 0.3 | Vitesse d'apprentissage R |
| Exploration base | Îµ | 0.1 | Taux exploration par dÃ©faut |

### 5.4 La couche MÃ©ta-SR â€” CONTRIBUTION PRINCIPALE â˜…

L'idÃ©e fondatrice : la carte d'incertitude a **exactement la mÃªme structure** que la carte prÃ©dictive. MÃªme indexation par Ã©tat, mÃªme granularitÃ© spatiale. Ce n'est pas un module externe qui observe la SR â€” c'est un **reflet** de la SR.

**Erreur de prÃ©diction SR scalaire par visite :**

```
Î´(s) = || e(s') + Î³ Â· M(s',:) - M(s,:) ||â‚‚
```

**Justification de la compression scalaire.** Le vecteur d'erreur TD complet Î´_vec(s) âˆˆ â„^N contient de l'information directionnelle (vers quels Ã©tats la prÃ©diction est mauvaise), mais la norme L2 suffit pour notre objectif principal : mesurer si l'agent sait que sa carte est fiable *en un Ã©tat donnÃ©*. La version scalaire permet de maintenir l'iso-structuralitÃ© (un scalaire par Ã©tat, comme M a une ligne par Ã©tat) tout en restant computationnellement lÃ©gÃ¨re. Une extension vectorielle U(s, s') â€” qui conserverait la structure complÃ¨te â€” est envisageable mais sort du scope de la v1. La compression scalaire est testÃ©e empiriquement : si le MI (corrÃ©lation entre U(s) et l'erreur rÃ©elle) est Ã©levÃ©, la compression ne perd pas d'information critique pour la calibration.

**Buffer d'erreurs glissant â€” Î”M_history(s) :**

Pour chaque Ã©tat s, buffer circulaire de taille K (dÃ©faut : 20) des Î´ observÃ©s lors des visites Ã  s.

**Carte d'incertitude â€” U(s) âˆˆ [0, 1] :**

```
U(s) = {
    mean(Î”M_history(s))           si visits(s) â‰¥ K
    U_max                          si visits(s) = 0
    U_prior Â· decay^(visits(s))    si 0 < visits(s) < K
}
```

**Signal de confiance â€” C(s) âˆˆ [0, 1] :**

```
C(s) = 1 - sigmoid(Î² Â· (U(s) - Î¸_C))
```

**DÃ©tection de changement :**

```
change_score = mean(U(s) for s in recently_visited)
change_detected = change_score > Î¸_change
```

**Exploration adaptative :**

```
Îµ_adaptive(s) = Îµ_min + (Îµ_max - Îµ_min) Â· U(s) / U_max
V_explore(s) = V(s) + Î» Â· U(s)
```

**ParamÃ¨tres mÃ©ta-SR â€” valeurs par dÃ©faut et justification :**

| ParamÃ¨tre | Symbole | DÃ©faut | Justification |
|-----------|---------|--------|---------------|
| Taille buffer | K | 20 | ~5 traversÃ©es complÃ¨tes d'une piÃ¨ce de FourRooms. Assez pour estimer la variance, assez petit pour dÃ©tecter les changements. |
| Prior d'incertitude | U_prior | 0.8 | Conservateur : un Ã©tat non visitÃ© est supposÃ© hautement incertain. |
| Decay du prior | decay | 0.85 | Chaque visite rÃ©duit l'incertitude prior de 15%. AprÃ¨s 10 visites, U â‰ˆ 0.16 (basse). |
| Pente sigmoÃ¯de confiance | Î² | 10 | Transition nette autour de Î¸_C. ValidÃ© par sweep [5, 10, 20] en Exp A. |
| Seuil de confiance | Î¸_C | 0.3 | Centre de la sigmoÃ¯de C(s). U < 0.3 â†’ haute confiance, U > 0.3 â†’ basse. |
| Seuil de changement | Î¸_change | 0.5 | DÃ©tection de changement. ValidÃ© par analyse ROC en Exp C. |
| Bonus exploration | Î» | 0.5 | Poids relatif exploration/exploitation dans V_explore. |
| Epsilon min | Îµ_min | 0.01 | Plancher d'exploration mÃªme en haute confiance. |
| Epsilon max | Îµ_max | 0.5 | Plafond d'exploration en haute incertitude. |

**Analyse de sensibilitÃ© (Exp A, phase prÃ©liminaire) :** Avant les comparaisons formelles, un sweep factoriel sur {U_prior, decay, Î², Î¸_C} sera rÃ©alisÃ© (4 paramÃ¨tres Ã— 3 valeurs = 81 configs, 10 runs chacune). Le critÃ¨re de sÃ©lection est l'ECE minimal sur la phase d'apprentissage stable. Les paramÃ¨tres sÃ©lectionnÃ©s sont ensuite fixÃ©s pour toutes les expÃ©riences. Ce sweep est reportÃ© en annexe pour Ã©viter le p-hacking.

**PropriÃ©tÃ© clÃ© â€” iso-structuralitÃ© :** U est indexÃ© par les mÃªmes Ã©tats que M. On peut superposer visuellement la carte prÃ©dictive et la carte d'incertitude. Les frontiÃ¨res de haute incertitude devraient correspondre aux frontiÃ¨res topologiques (portes, zones inexplorÃ©es, zones perturbÃ©es). C'est cette propriÃ©tÃ© qui est testÃ©e dans l'Exp A.

---

## 6. Protocole expÃ©rimental

Trois expÃ©riences profondes au lieu de cinq superficielles. Chacune teste une prÃ©diction spÃ©cifique.

### 6.1 ExpÃ©rience A â€” Calibration mÃ©tacognitive (teste P1 + P2)

**Question :** Le signal de confiance C(s) est-il calibrÃ© ? La carte U(s) est-elle iso-structurale Ã  M ?

**Protocole :**

1. **Phase apprentissage** (300 Ã©pisodes) : monde stable, 4 piÃ¨ces, goal fixe. L'agent apprend M et construit U.
2. **Phase exploration** (100 Ã©pisodes) : on ouvre une nouvelle zone (5e piÃ¨ce) jamais vue.
3. **Phase perturbation** (100 Ã©pisodes) : on dÃ©place le goal dans la nouvelle zone.
4. Ã€ chaque step, l'agent Ã©met C(s) â€” sa confiance.

**MÃ©triques :**

**Calibration â€” Expected Calibration Error (ECE) :**

```
ECE = Î£_b (|B_b| / N) Â· |accuracy(B_b) - confidence(B_b)|
```

On dÃ©coupe les prÃ©dictions en 10 bins de confiance. Pour chaque bin, on compare la confiance moyenne C(s) et le taux de Â« prÃ©dictions fiables Â». **DÃ©finition opÃ©rationnelle de l'accuracy :** une prÃ©diction est considÃ©rÃ©e comme fiable quand l'erreur rÃ©elle de la SR est faible, i.e. ||M(s,:) - M*(s,:)||â‚‚ < Ï„_accuracy, oÃ¹ M* est la vraie matrice de transition. Ce choix est cohÃ©rent avec ce que C(s) est censÃ© prÃ©dire : non pas la stochasticitÃ© des transitions (nulle dans MiniGrid â€” l'environnement est dÃ©terministe), mais la *fiabilitÃ© de la carte M elle-mÃªme*. Le seuil Ï„_accuracy est fixÃ© au 50e percentile de ||M - M*|| sur l'ensemble des Ã©tats, de sorte que la baseline d'accuracy est ~50%. Cela garantit une dynamique informative dans le reliability diagram.

**Iso-structuralitÃ© â€” CorrÃ©lation spatiale :**

```
Ï = corr(U(s), d(s, frontier))
```

La carte d'incertitude devrait corrÃ©ler avec la distance aux frontiÃ¨res topologiques (portes, zones inexplorÃ©es). On mesure aussi la corrÃ©lation entre U(s) et l'erreur rÃ©elle de la SR (ground truth) :

```
MI = corr(U(s), ||M(s,:) - M*(s,:)||)  oÃ¹ M* est la vraie matrice de transition
```

MI = Metacognitive Index. C'est la mÃ©trique reine : l'agent sait-il ce qu'il ne sait pas ?

**Reliability diagram :** graphique confiance dÃ©clarÃ©e vs. accuracy observÃ©e, par bin. Une courbe sur la diagonale = calibration parfaite.

**Conditions :**

| Condition | Signal de confiance | Description |
|-----------|--------------------|-------------|
| **PRISM** | C(s) = f(U(s)), U structurÃ© spatialement | Notre approche |
| SR-Global | Confiance = f(erreur TD moyenne globale) | Incertitude non-structurÃ©e |
| SR-Count | Confiance = f(1/âˆšvisits(s)) | Count-based (Machado-like) |
| SR-Bayesian | Posterior sur V via rÃ©gression linÃ©aire | Successor Uncertainties-like |
| Random-Conf | Confiance alÃ©atoire | Baseline plancher |

**CritÃ¨res de succÃ¨s :**
- ECE(PRISM) < 0.15
- MI(PRISM) > 0.5 (corrÃ©lation modÃ©rÃ©e Ã  forte)
- ECE(PRISM) < ECE(SR-Global) et ECE(SR-Count) â€” la structure spatiale aide la calibration
- Le reliability diagram montre une corrÃ©lation positive claire

**Visualisations :**
- Heatmap de M pour quelques Ã©tats sources (validation SR standard)
- Heatmap de U superposÃ©e au monde â€” la carte d'incertitude
- Reliability diagram par condition
- Ã‰volution temporelle de U aprÃ¨s perturbation (animation ou sÃ©quence)
- Top-6 eigenvectors de M (validation spectrale standard)

### 6.2 ExpÃ©rience B â€” Exploration dirigÃ©e par incertitude structurelle (teste P3)

**Question :** L'exploration guidÃ©e par U(s) (structurÃ© spatialement) est-elle plus efficace que les alternatives ?

**Protocole :**

1. Grand monde MiniGrid (19Ã—19) avec 4+ piÃ¨ces
2. 4 goals cachÃ©s, un par piÃ¨ce (l'agent ne les connaÃ®t pas au dÃ©part)
3. L'agent doit trouver les 4 goals le plus vite possible
4. Comparer l'efficacitÃ© d'exploration selon la stratÃ©gie

**Conditions :**

| Condition | StratÃ©gie d'exploration | Signal directeur |
|-----------|------------------------|------------------|
| **PRISM** | V_explore = V + Î»Â·U(s) | Carte U structurÃ©e |
| SR-Oracle | V + Î»Â·||M(s,:) - M*(s,:)|| | Erreur rÃ©elle (plafond thÃ©orique) |
| SR-Îµ-greedy | Îµ fixe = 0.1 | Aucun |
| SR-Îµ-decay | Îµ dÃ©croissant | Aucun |
| SR-Count-Bonus | V + Î»/âˆšvisits(s) | Comptage (Machado-like) |
| SR-Norm-Bonus | V + Î»/||M(s,:)|| | Norme SR (Machado 2020) |
| SR-Posterior | Posterior sampling sur V | BayÃ©sien (Janz-like) |
| Random | UniformÃ©ment alÃ©atoire | Baseline plancher |

**SR-Oracle** connaÃ®t les vraies erreurs de M et les utilise comme bonus. C'est un plafond de performance â€” aucun agent rÃ©aliste ne peut faire mieux. Le ratio (performance PRISM - Random) / (performance Oracle - Random) quantifie quelle fraction du gain thÃ©orique PRISM capture (Â« efficiency ratio Â»).

**MÃ©triques :**
- Steps pour trouver les 4 goals (moyenne sur 100 runs)
- Couverture (% d'Ã©tats visitÃ©s) vs. steps
- Redondance : ratio revisites / nouvelles visites
- CorrÃ©lation entre l'ordre de visite des rÃ©gions et leur U(s)
- Efficiency ratio : (steps_Random - steps_PRISM) / (steps_Random - steps_Oracle) â€” fraction du gain thÃ©orique capturÃ©e

**CritÃ¨re de succÃ¨s :** PRISM trouve les 4 goals en significativement moins de steps que SR-Îµ-greedy et SR-Count-Bonus.

**Test diffÃ©rentiel clÃ© :** PRISM vs. SR-Count-Bonus isole l'apport de la structure. Les deux donnent un bonus d'exploration, mais PRISM utilise l'erreur de prÃ©diction SR (structurÃ©e) tandis que Count-Bonus utilise les visites (non-structurÃ©e). Si PRISM gagne, c'est que la structure prÃ©dictive de la SR apporte quelque chose au-delÃ  du simple comptage.

### 6.3 ExpÃ©rience C â€” Adaptation au changement (teste P1 + P2 en dynamique)

**Question :** L'agent dÃ©tecte-t-il les changements et adapte-t-il son comportement, tout en maintenant une confiance calibrÃ©e ?

**Protocole :**

1. **Phase stable** (200 Ã©pisodes) : monde fixe, l'agent maÃ®trise l'environnement.
2. **Perturbation de type R** (100 Ã©pisodes) : goal dÃ©placÃ©. M reste valide, R change.
3. **Re-stabilisation** (100 Ã©pisodes) : l'agent se rÃ©adapte.
4. **Perturbation de type M** (100 Ã©pisodes) : porte bloquÃ©e. M devient invalide, R ne change pas.
5. **Re-stabilisation finale** (100 Ã©pisodes).

Ce design teste la prÃ©diction SR classique (Momennejad 2017) : l'adaptation au changement de R devrait Ãªtre rapide (seul R est mis Ã  jour), l'adaptation au changement de M devrait Ãªtre lente (toute la matrice doit Ãªtre rÃ©apprise).

**PrÃ©diction quantitative de l'asymÃ©trie R/M.** Pour un changement de R (goal dÃ©placÃ©), l'adaptation nÃ©cessite ~O(1/Î±_R) Ã©pisodes pour converger â€” avec Î±_R = 0.3, cela donne ~3-5 Ã©pisodes. Pour un changement de M (porte bloquÃ©e), les lignes de M correspondant aux N_affected Ã©tats dont les transitions changent doivent Ãªtre rÃ©apprises â€” cela prend ~O(N_affected / Î±_M) Ã©pisodes. Dans FourRooms, bloquer une porte affecte ~8-12 Ã©tats adjacents Ã  la porte ; avec Î±_M = 0.1, cela donne ~80-120 Ã©pisodes. Le ratio prÃ©dit est donc latence_M / latence_R â‰ˆ 15-40Ã—. Si le ratio observÃ© tombe significativement en dehors de cette plage, cela pointerait vers un mÃ©canisme non-SR (trop bas â†’ model-based ; trop haut â†’ pas de rÃ©apprentissage M).

**MÃ©triques :**
- **Latence de dÃ©tection** : Ã©pisodes avant `change_detected = true`
- **Latence d'adaptation** : Ã©pisodes pour retrouver 80% de la performance prÃ©-perturbation
- **Calibration dynamique** : ECE mesurÃ© dans une fenÃªtre glissante de 20 Ã©pisodes â€” la calibration se maintient-elle pendant et aprÃ¨s les transitions ?
- **AsymÃ©trie R vs. M** : ratio latence_M / latence_R â€” devrait Ãªtre >> 1 si la SR est bien le mÃ©canisme sous-jacent

**Conditions :**

| Condition | Description |
|-----------|-------------|
| **PRISM** | Agent complet avec mÃ©ta-SR et dÃ©tection |
| SR-Blind | Agent SR sans monitoring (Îµ fixe) |
| Q-Learning | Model-free classique (Stable-Baselines3) |

**CritÃ¨res de succÃ¨s :**
- PRISM dÃ©tecte les changements en < 10 Ã©pisodes
- Latence d'adaptation : PRISM â‰¤ 0.5 Ã— SR-Blind
- AsymÃ©trie R/M observable (confirmation de la signature SR)
- ECE reste < 0.20 mÃªme pendant les transitions

### 6.4 Plan d'analyse statistique

**Nombre de runs et puissance.** Chaque condition est exÃ©cutÃ©e 100 fois avec des seeds alÃ©atoires diffÃ©rentes (Exp A et C : 100 runs Ã— ~500 Ã©pisodes ; Exp B : 100 runs Ã— durÃ©e variable). Ce nombre garantit une puissance statistique suffisante pour dÃ©tecter des diffÃ©rences d'effet moyen (Cohen's d â‰¥ 0.5) avec Î± = 0.05.

**Tests de comparaison (Exp A, B).** Les distributions de mÃ©triques (ECE, steps, MI) entre conditions ne sont pas supposÃ©es normales. Les comparaisons deux-Ã -deux utilisent le test de Mann-Whitney U (unilatÃ©ral quand la direction est prÃ©dite, bilatÃ©ral sinon). La correction de Holm-Bonferroni est appliquÃ©e pour les comparaisons multiples â€” seules les comparaisons prÃ©-spÃ©cifiÃ©es dans les critÃ¨res de succÃ¨s sont testÃ©es, pas de fishing.

**Intervalles de confiance.** Les intervalles de confiance Ã  95% sur l'ECE et le MI sont calculÃ©s par bootstrap non-paramÃ©trique (10 000 re-Ã©chantillonnages). Les barres d'erreur dans les figures reprÃ©sentent ces intervalles.

**Tests de calibration (Exp A, C).** En plus de l'ECE, le test de Hosmer-Lemeshow est appliquÃ© pour Ã©valuer formellement la qualitÃ© de la calibration dans chaque condition. Un p > 0.05 indique une calibration acceptable.

**CorrÃ©lations (Exp A â€” iso-structuralitÃ©).** Les corrÃ©lations Ï et MI sont reportÃ©es avec des intervalles de confiance bootstrap. La significativitÃ© est Ã©valuÃ©e par un test de permutation (1000 permutations).

**Taille d'effet.** Toutes les comparaisons reportent le Cohen's d (ou r de rang pour Mann-Whitney) en plus du p-value. Un rÃ©sultat statistiquement significatif mais avec une taille d'effet faible (d < 0.3) sera discutÃ© comme tel.

---

## 7. Stack technique

### 7.1 DÃ©pendances

```
Python 3.11+
minigrid >= 2.3         # environnement FourRooms (Farama)
gymnasium >= 0.29       # interface standard RL
numpy >= 1.24
scipy >= 1.11           # dÃ©composition spectrale
matplotlib >= 3.7
seaborn                 # reliability diagrams, heatmaps
pandas                  # logging des rÃ©sultats
tqdm                    # progress bars
pytest                  # tests
stable-baselines3       # baselines Q-learning / DQN
```

### 7.2 Structure du projet

```
prism/
â”œâ”€â”€ master.md                          # â† ce document
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ env/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dynamics_wrapper.py        # [Ã€ CODER] Wrapper perturbations sur MiniGrid
â”‚   â”‚   â”œâ”€â”€ state_mapper.py            # [Ã€ CODER] Mapping position MiniGrid â†’ index SR
â”‚   â”‚   â””â”€â”€ perturbation_schedule.py   # [Ã€ CODER] Configs de schedules
â”‚   â”‚
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ sr_layer.py                # [ADAPTÃ‰] SR tabulaire (depuis Juliani 2019)
â”‚   â”‚   â”œâ”€â”€ meta_sr.py                 # [Ã€ CODER] â˜… Carte U(s), signal C(s), dÃ©tection
â”‚   â”‚   â”œâ”€â”€ controller.py              # [Ã€ CODER] â˜… Îµ adaptatif, V_explore, "je ne sais pas"
â”‚   â”‚   â””â”€â”€ prism_agent.py             # [Ã€ CODER] â˜… Agent complet assemblant les couches
â”‚   â”‚
â”‚   â”œâ”€â”€ baselines/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ sr_blind.py                # [Ã€ CODER] SR sans mÃ©ta-monitoring
â”‚   â”‚   â”œâ”€â”€ sr_count.py                # [Ã€ CODER] SR + count-based bonus
â”‚   â”‚   â”œâ”€â”€ sr_bayesian.py             # [Ã€ CODER] SR + rÃ©gression bayÃ©sienne (Janz-like)
â”‚   â”‚   â””â”€â”€ sb3_baselines.py           # [WRAPPER] Q-learning via Stable-Baselines3
â”‚   â”‚
â”‚   â””â”€â”€ analysis/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ calibration.py             # [Ã€ CODER] â˜… ECE, reliability diagrams, MI
â”‚       â”œâ”€â”€ spectral.py                # [ADAPTÃ‰] Eigenvectors M (depuis Chelu)
â”‚       â”œâ”€â”€ visualization.py           # [Ã€ CODER] Heatmaps U/M superposÃ©es, animations
â”‚       â””â”€â”€ metrics.py                 # [Ã€ CODER] Exploration efficiency, latence, etc.
â”‚
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ exp_a_calibration.py           # Exp A â€” calibration mÃ©tacognitive
â”‚   â”œâ”€â”€ exp_b_exploration.py           # Exp B â€” exploration dirigÃ©e
â”‚   â”œâ”€â”€ exp_c_adaptation.py            # Exp C â€” adaptation au changement
â”‚   â””â”€â”€ run_all.py                     # Script batch
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_sr_validation.ipynb         # VÃ©rification que la SR converge (sanity check)
â”‚   â”œâ”€â”€ 02_meta_sr_demo.ipynb          # Visualisation mÃ©ta-SR interactive
â”‚   â””â”€â”€ 03_results_analysis.ipynb      # Analyse + figures finales
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_dynamics_wrapper.py
â”‚   â”œâ”€â”€ test_sr_layer.py
â”‚   â”œâ”€â”€ test_meta_sr.py
â”‚   â””â”€â”€ test_calibration.py
â”‚
â””â”€â”€ results/                           # GÃ©nÃ©rÃ© automatiquement
    â”œâ”€â”€ exp_a/
    â”œâ”€â”€ exp_b/
    â””â”€â”€ exp_c/
```

**LÃ©gende :**
- â˜… = contribution PRISM (code original)
- [ADAPTÃ‰] = adaptÃ© depuis code open-source existant
- [WRAPPER] = mince couche d'intÃ©gration sur une librairie existante
- [Ã€ CODER] sans â˜… = code de plomberie nÃ©cessaire mais pas innovant

**Ratio estimÃ© :** ~40% code original (mÃ©ta-SR, calibration, contrÃ´leur), ~30% adaptÃ©, ~30% wrappers et intÃ©gration.

---

## 8. Plan d'implÃ©mentation

### Phase 1 â€” Assemblage (semaines 1-2)

Objectif : agent SR fonctionnel dans MiniGrid, zÃ©ro contribution originale.

- [ ] Installer MiniGrid, vÃ©rifier FourRooms fonctionne
- [ ] `state_mapper.py` â€” mapping position MiniGrid â†’ index pour matrice SR
- [ ] `sr_layer.py` â€” adapter l'implÃ©mentation SR tabulaire de Juliani
- [ ] `dynamics_wrapper.py` â€” wrapper perturbations (reward shift, door block)
- [ ] `spectral.py` â€” adapter le code de visualisation eigenvectors (Chelu)
- [ ] Notebook `01_sr_validation.ipynb` â€” sanity check : SR converge, eigenvectors ok
- [ ] Tests unitaires : wrapper, SR layer, state mapper

**Milestone :** L'agent SR navigue vers le goal dans FourRooms. Les heatmaps de M et les eigenvectors sont cohÃ©rents avec Stachenfeld 2017.

### Phase 2 â€” MÃ©ta-SR et calibration (semaines 3-5) â˜…

Objectif : implÃ©menter la contribution principale et exÃ©cuter l'Exp A.

- [ ] `meta_sr.py` â€” buffer d'erreurs, carte U(s), signal C(s), dÃ©tection
- [ ] `controller.py` â€” Îµ adaptatif, V_explore, signal "je ne sais pas"
- [ ] `prism_agent.py` â€” assemblage agent complet
- [ ] `calibration.py` â€” ECE, reliability diagrams, Metacognitive Index
- [ ] `visualization.py` â€” superposition U/M, animations
- [ ] Baselines : `sr_blind.py`, `sr_count.py`, `sr_bayesian.py`
- [ ] **Sweep hyperparamÃ¨tres mÃ©ta-SR** â€” 81 configs, critÃ¨re ECE minimal (voir Â§5.4)
- [ ] **ExÃ©cuter Exp A** â€” calibration mÃ©tacognitive
- [ ] Notebook `02_meta_sr_demo.ipynb`

**Milestone :** PRISM produit un signal de confiance calibrÃ© (ECE < 0.15). Le reliability diagram montre une corrÃ©lation positive. MI > 0.5.

### Phase 3 â€” Exploration et adaptation (semaines 6-8) â˜…

Objectif : exÃ©cuter les Exp B et C, comparaisons avec baselines.

- [ ] Config grand monde pour Exp B (19Ã—19, 4+ piÃ¨ces, 4 goals cachÃ©s)
- [ ] **ExÃ©cuter Exp B** â€” exploration dirigÃ©e, toutes conditions
- [ ] **ExÃ©cuter Exp C** â€” adaptation au changement (perturbations R puis M)
- [ ] `sb3_baselines.py` â€” wrapper Stable-Baselines3 pour Q-learning baseline
- [ ] SR-Oracle baseline (utilise M* comme signal â€” plafond thÃ©orique Exp B)
- [ ] Analyse croisÃ©e des 3 expÃ©riences
- [ ] Notebook `03_results_analysis.ipynb` â€” figures finales
- [ ] RÃ©daction du rapport de rÃ©sultats

**Milestone :** PRISM bat les baselines sur l'exploration. L'asymÃ©trie R/M confirme la signature SR. La calibration se maintient en dynamique.

---

## 9. MÃ©triques globales

### Tableau de bord

| Exp | MÃ©trique | Baseline | Cible PRISM | Teste |
|-----|----------|----------|-------------|-------|
| A | ECE | â€” | < 0.15 | P1 |
| A | Metacognitive Index (MI) | â€” | > 0.5 | P2 |
| A | ECE vs. SR-Global | ECE(SR-Global) | ECE(PRISM) < ECE(SR-Global) | P1 |
| B | Steps pour 4 goals | SR-Îµ-greedy | âˆ’30% | P3 |
| B | Steps PRISM vs. SR-Count-Bonus | SR-Count-Bonus | PRISM < Count-Bonus | P3 (structure) |
| B | Efficiency ratio (PRISM vs. Oracle) | SR-Oracle | > 0.5 (capture >50% du gain thÃ©orique) | P3 (plafond) |
| C | Latence de dÃ©tection | SR-Blind | < 10 Ã©pisodes | P1 |
| C | Latence adaptation PRISM / SR-Blind | SR-Blind | â‰¤ 0.5Ã— | P2 |
| C | AsymÃ©trie latence_M / latence_R | â€” | 15â€“40Ã— (dÃ©rivÃ© analytiquement) | Signature SR |
| C | ECE pendant transitions | â€” | < 0.20 | P1 dynamique |

### MÃ©triques transversales

- **Metacognitive Index (MI)** = corr(U(s), erreur rÃ©elle SR). MÃ©trique reine : l'agent sait-il ce qu'il ne sait pas ?
- **Calibration Maintenance** = ECE mesurÃ© en fenÃªtre glissante. La calibration se dÃ©grade-t-elle ?
- **Structure Advantage** = gain PRISM vs. SR-Count-Bonus. Isole l'apport de la structure SR.

---

## 10. Extensions futures

### Court terme (si les rÃ©sultats sont solides)

- **SR multi-Ã©chelle** : maintenir plusieurs M avec diffÃ©rents Î³, inspirÃ© de l'axe longitudinal de l'hippocampe. Tester si les cartes U Ã  diffÃ©rentes Ã©chelles capturent diffÃ©rents types d'incertitude.
- **Replay** : rejeu d'expÃ©riences en phases offline pour consolider M, inspirÃ© du replay hippocampique. Tester l'impact sur la stabilitÃ© de U.
- **Arbitrage SR/MB** : ajouter un planificateur model-based et utiliser U(s) pour l'arbitrage (Russek et al. 2017). ReportÃ© de la v1 mais prÃªt architecturalement.

### Moyen terme

- **Deep SR** : remplacer la matrice tabulaire par un rÃ©seau (Chua et al. 2024 comme point de dÃ©part). La mÃ©ta-SR peut-elle fonctionner sur des reprÃ©sentations apprises ?
- **Espaces non-spatiaux** : appliquer PRISM Ã  un espace sÃ©mantique (Stoewer et al. 2023) â€” la mÃ©tacognition SR fonctionne-t-elle au-delÃ  de la navigation ?

### Recherche

- Comparer la structure spectrale de la SR + mÃ©ta-SR artificielles avec les donnÃ©es Ã©lectrophysiologiques
- Formaliser le lien mÃ©ta-SR â†” Ã©nergie libre variationnelle (active inference)
- Explorer si la mÃ©ta-SR est une approximation de l'incertitude bayÃ©sienne (Successor Uncertainties) et sous quelles conditions

---

## 11. RÃ©fÃ©rences

### Fondations SR

| RÃ©f | Apport |
|-----|--------|
| Dayan (1993) â€” *Neural Computation* | Formalisme SR original |
| Stachenfeld et al. (2017) â€” *Nature Neuroscience* | Hippocampe comme carte prÃ©dictive |
| Gershman (2018) â€” *J. Neuroscience* | Survey SR : logique computationnelle et substrats neuronaux |
| Momennejad et al. (2017) â€” *Nature Human Behaviour* | Preuves comportementales SR chez l'humain |
| Russek et al. (2017) â€” *PLoS Comp Bio* | SRâ€“MB hybride, replay, Dyna-SR |
| Barreto et al. (2017) â€” *NeurIPS* | Successor features pour le transfert |

### Espaces cognitifs

| RÃ©f | Apport |
|-----|--------|
| Bellmund et al. (2018) â€” *Science* | Codes spatiaux pour la pensÃ©e humaine |
| Theves et al. (2020) â€” *J. Neuroscience* | Hippocampe cartographie l'espace conceptuel |
| Stoewer et al. (2023) â€” *Scientific Reports* | SR sur espaces sÃ©mantiques (NN artificiels) |
| Ekman et al. (2023) â€” *eLife* | SR dans le cortex visuel |

### MÃ©tacognition et hippocampe

| RÃ©f | Apport |
|-----|--------|
| Ambrogioni, L. & Ã“lafsdÃ³ttir, H. F. (2023) â€” *Trends in Cognitive Sciences*, 27(8), 702-712 | ThÃ¨se fondatrice de PRISM : mÃ©ta-carte hippocampique comme module de mÃ©ta-apprentissage |
| Allen et al. (2017) â€” *NeuroImage* | CorrÃ©lats microstructuraux mÃ©tacognitionâ€“hippocampe |
| Qiu et al. (2024) â€” *Communications Biology* | Hippocampe + OFC pour espaces abstraits |

### SR et incertitude â€” positionnement direct

| RÃ©f | Apport | Relation Ã  PRISM |
|-----|--------|------------------|
| Janz et al. (2019) â€” *NeurIPS* | Successor Uncertainties | Approche bayÃ©sienne â€” PRISM compare |
| Machado et al. (2020) â€” *AAAI* | Count-based exploration + SR | Norme SR â€” PRISM utilise comme baseline |
| Flennerhag et al. (2020) â€” *DeepMind* | TD uncertainties pour exploration | Signal TD â€” PRISM Ã©tend en carte structurÃ©e |
| Chua et al. (2024) â€” *arXiv* | Simple Successor Features | Deep SF depuis pixels â€” extension future |

### MÃ©tacognition en IA â€” positionnement direct

| RÃ©f | Apport | Relation Ã  PRISM |
|-----|--------|------------------|
| Valiente & Pilly (2024/2025) â€” MUSE | Self-assessment + self-regulation | Framework gÃ©nÃ©ral â€” PRISM spÃ©cifique SR |
| Kawato et al. (2021) â€” *Biol. Cybernetics* | Internal models â†’ metacognitive AI | Responsibility signal â‰ˆ mÃ©ta-SR |
| Steyvers & Peters (2025) â€” *Perspectives Psych. Science* | MÃ©tacognition LLMs + calibration | MÃ©triques ECE â€” PRISM emprunte |

### Global Neuronal Workspace â€” cadre englobant

| RÃ©f | Apport | Relation Ã  PRISM |
|-----|--------|------------------|
| Dehaene, Kerszberg & Changeux (1998) â€” *PNAS* | ModÃ¨le neuronal du GNW | Cadre englobant â€” PRISM = processeur spÃ©cialisÃ© |
| Dehaene & Changeux (2011) â€” *Neuron* | GNW : approches expÃ©rimentales et thÃ©oriques | Ignition, broadcast, seuils |
| Deco, Vidaurre & Kringelbach (2021) â€” *Nature Human Behaviour* | Functional rich club = workspace empirique | Hippocampe dans le core du workspace |
| Whyte & Smith (2020) â€” *Progress in Neurobiology* | Predictive Global Workspace (GNW + active inference) | Pont direct : erreurs de prÃ©diction dans le workspace |

### Assets techniques

| Asset | Source | Usage |
|-------|--------|-------|
| MiniGrid | github.com/Farama-Foundation/Minigrid | Environnement |
| SR tabulaire tutorial | Juliani (2019) | Base agent SR |
| Temporal abstraction (spectral) | github.com/veronicachelu/temporal_abstraction | Visualisation eigenvectors |
| SR/MB hybride code | github.com/evanrussek | RÃ©fÃ©rence arbitrage |
| Stable-Baselines3 | github.com/DLR-RM/stable-baselines3 | Baselines RL |

---

*DerniÃ¨re mise Ã  jour : 2026-02-14*
